{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patch motion trajectories to per-particle trajectories\n",
    "\n",
    "This notebook will derive per-particle trajectories from patch motion trajectories, by interpolating the patch motion spline functions at the particle pick locations.\n",
    "\n",
    "## Setup\n",
    "We begin by importing libraries, connecting to the CryoSPARC instance, and defining the functions which will interpolate the patch motion splines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "import io\n",
    "\n",
    "import numpy as np\n",
    "from scipy.ndimage import map_coordinates\n",
    "\n",
    "from cryosparc.tools import CryoSPARC\n",
    "from cryosparc import dataset\n",
    "\n",
    "with open(Path(\"~/instance-info.json\").expanduser(), \"r\") as f:\n",
    "    instance_info = json.load(f)\n",
    "\n",
    "cs = CryoSPARC(**instance_info)\n",
    "assert cs.test_connection()\n",
    "\n",
    "def spline_interp(gridshape, spl, pix):\n",
    "    K_Z, K_Y, K_X = spl.shape\n",
    "    mz, my, mx = gridshape\n",
    "    coords = pix * np.array(\n",
    "        [(K_Z - 1) / float(max(mz - 1, 1)), (K_Y - 1) / float(max(my - 1, 1)), (K_X - 1) / float(max(mx - 1, 1))],\n",
    "        np.float32,\n",
    "    ).reshape((3,) + (1,) * (pix.ndim - 1))\n",
    "\n",
    "    res = map_coordinates(\n",
    "        np.pad(spl, 1, \"reflect\", reflect_type=\"odd\"), \n",
    "        coords + 1, \n",
    "        mode=\"constant\", \n",
    "        prefilter=False\n",
    "    )\n",
    "    return res\n",
    "\n",
    "def spline_interp_traj(gridshape, splxy, pos):\n",
    "    mz, my, mx = gridshape\n",
    "    N_P = pos.shape[0]\n",
    "    pix = np.zeros((3, N_P, mz), dtype=np.float32)\n",
    "    pix[0] = np.arange(mz).reshape(1, -1)\n",
    "    pix[1] = pos[:, 1].reshape(-1, 1)\n",
    "    pix[2] = pos[:, 0].reshape(-1, 1)\n",
    "    res = np.empty((N_P, mz, 2), np.float32)\n",
    "    res[:, :, 0] = spline_interp(gridshape, splxy[0], pix)\n",
    "    res[:, :, 1] = spline_interp(gridshape, splxy[1], pix)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define the project, workspace, and jobs from which we will load data.\n",
    "Eventually, particles with local trajectories will be saved in new jobs in `dest_workspace`.\n",
    "Ideally, `micrograph_source` is a Patch CTF Estimation job which is downstream of a Patch Motion Correction job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_uuid   = \"P423\"\n",
    "dest_workspace = \"W4\"   # <-- particles with local tracectories will be saved to this workspace\n",
    "\n",
    "particle_source   = \"J45\"\n",
    "micrograph_source = \"J29\" # <-- ideally a patch CTF job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating an external job\n",
    "We now create the [external job](https://tools.cryosparc.com/api/job.html#cryosparc.job.ExternalJob) which will hold the particles with updated trajectories.\n",
    "Connecting the particles and micrographs as inputs has two main advantages:\n",
    "\n",
    "1. The external job is in the correct position in the tree view\n",
    "2. The input particles' fields will be [passed through](https://guide.cryosparc.com/guides-for-v3/job-builder-tutorial#passthrough-results). This makes the output dataset much smaller.\n",
    "\n",
    "We also add new fields to the particles dataset.\n",
    "These fields will store the local motion trajectories.\n",
    "Currently, the best way to determine what fields are necessary for a given result is to look at a job that produces that result.\n",
    "In this case, you could inspect the output of a Local Motion Correction job to determine that these fields are necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "project = cs.find_project(project_uuid)\n",
    "job = project.create_external_job(dest_workspace, title=\"Patch to Local\")\n",
    "job.connect(\"micrographs\", micrograph_source, \"exposures\", slots=[\"movie_blob\", \"spline_motion\", \"rigid_motion\"])\n",
    "job.connect(\"particles\", particle_source, \"particles\", slots=[\"location\"])\n",
    "job.add_output(\"particle\", \"particles\", slots=[\"motion\"], passthrough=\"particles\")\n",
    "\n",
    "pcls = job.load_input(\"particles\", [\"location\"])\n",
    "mics = job.load_input(\"micrographs\", [\"movie_blob\", \"spline_motion\", \"rigid_motion\"])\n",
    "\n",
    "job.mkdir(\"traj\")\n",
    "\n",
    "pcls.add_fields([\n",
    "    ('motion/type', 'O'), \n",
    "    ('motion/path', 'O'), \n",
    "    ('motion/idx','u4'), \n",
    "    ('motion/frame_start', 'u4'), \n",
    "    ('motion/frame_end', 'u4'), \n",
    "    ('motion/zero_shift_frame', 'u4'), \n",
    "    ('motion/psize_A', 'f4')\n",
    "])\n",
    "\n",
    "particle_subsets = pcls.split_by('location/micrograph_uid')\n",
    "particle_outsubsets = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the job\n",
    "We now perform the necessary computation to translate the patch motion splines into local motion trajectories.\n",
    "Doing this calculation with a [context manager](https://realpython.com/python-with-statement/#the-with-statement) provides two benefits:\n",
    "1. We don't need to remember to mark the job as \"Done\" -- this is done automatically when we exit the \"with\" block.\n",
    "2. If there is an error during execution, the job will automatically be marked as \"Failed\" and the python error will be added to the job's log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with job.run():\n",
    "    for uid in mics[\"uid\"]:\n",
    "        if uid not in particle_subsets:\n",
    "            continue\n",
    "        \n",
    "        subset = particle_subsets[uid]\n",
    "        particle_outsubsets.append(subset)\n",
    "        movie = mics.mask(mics['uid']==uid).rows()[0]\n",
    "        mpsz = movie['movie_blob/psize_A']\n",
    "\n",
    "        # load trajectories\n",
    "        tpath_spl = movie['spline_motion/path']\n",
    "        tpsz_spl  = movie['spline_motion/psize_A']\n",
    "        assert tpsz_spl != 0\n",
    "        with project.download(tpath_spl) as F:\n",
    "            f = io.BytesIO(F.read())\n",
    "            splxy = np.load(f)\n",
    "\n",
    "        tpath_rig = movie['rigid_motion/path']\n",
    "        tpsz_rig  = movie['rigid_motion/psize_A']\n",
    "        assert tpsz_rig != 0\n",
    "        assert tpsz_rig == tpsz_spl\n",
    "        assert tpsz_rig == mpsz\n",
    "        with project.download(tpath_rig) as F:\n",
    "            f = io.BytesIO(F.read())\n",
    "            t_rigid = np.load(f)\n",
    "\n",
    "        N_Z, ny, nx = movie['movie_blob/shape']\n",
    "\n",
    "        pcl_coords = np.zeros((len(subset),2))\n",
    "        pcl_coords[:,0] = subset['location/center_x_frac'] * nx\n",
    "        pcl_coords[:,1] = subset['location/center_y_frac'] * ny\n",
    "\n",
    "        # pos_raw is the patch center locations, as (x,y) pairs, in raw movie coords \n",
    "        pos_raw = np.array( pcl_coords ).astype(np.int32).copy(order='C')\n",
    "    \n",
    "        # to get the absolute trajectory:\n",
    "        gridshape = (N_Z, ny, nx) # shape of input movie\n",
    "        # pos_raw = x,y pairs of integers for center of particles in raw movie coords\n",
    "        ts = (spline_interp_traj(gridshape, splxy, pos_raw) + t_rigid.reshape(1,N_Z,2)).astype(np.float32)\n",
    "        \n",
    "        opath = \"trajs/\" + str(uid) + '.npy'\n",
    "        outfile = io.BytesIO()\n",
    "        np.save(outfile, ts)\n",
    "        outfile.seek(0)\n",
    "        job.upload(opath, outfile)\n",
    "        opath = os.path.join(job.uid, opath)\n",
    "\n",
    "        subset['motion/type'][:] = 'particle'\n",
    "        subset['motion/idx'][:] = np.arange(len(subset))\n",
    "        subset['motion/zero_shift_frame'][:] = 0 # NOT USED \n",
    "        subset['motion/psize_A'][:] = mpsz\n",
    "        subset['motion/path'][:] = opath\n",
    "\n",
    "        assert movie['rigid_motion/frame_start'] == 0\n",
    "        assert movie['rigid_motion/frame_end'] == N_Z\n",
    "        subset['motion/frame_start'][:] = 0\n",
    "        subset['motion/frame_end'][:] = N_Z\n",
    "\n",
    "    full_particle_dset = dataset.Dataset.append_many(*particle_outsubsets)\n",
    "    full_particle_dset = full_particle_dset.filter_prefixes(['motion','location'])\n",
    "\n",
    "    job.save_output(\"particles\", full_particle_dset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
